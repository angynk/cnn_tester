version: "3.8"

services:

  mobility-aids:
    container_name: mobility-aids
    # The following lines define the NVIDIA runtime and give the container 
    # access to all available GPU devices on the host.
    # INFO: comment them out if you don't have access to a GPU, as the container will not start otherwise.
    runtime: nvidia
    image: nvcr.io/nvidia/pytorch:22.02-py3
    ipc: host
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
    # The context used when building the image.
    # In this case it is the project's root, where the docker-compose build command is executed from
    build:
      context: ./
    # 
    stdin_open: true
    tty: true
    # Here we mount the ./src directory containing our code from the host machine into the container.
    # This way, our container always gets the most up-to-date state of our code base, without needing to rebuild the image! :)
    volumes:
      - ./src/:/work/src
    #  - ./dataset:/work/dataset
      - ./outputs:/work/outputs
    # This forwards the container port 5678 to host port 5678, where we wil start the debugger from within VSCode.
    ports:
      - 5678:5678     
    command:   python src/train.py